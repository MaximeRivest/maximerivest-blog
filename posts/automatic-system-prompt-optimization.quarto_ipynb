{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Automatic System Prompt Optimization\"\n",
        "date: 2025-07-21\n",
        "author: Maxime Rivest\n",
        "description: \"In this tutorial, I will teach you how to automatically optimize your System Prompt.\"\n",
        "draft: false\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-location: right\n",
        "    code-tools: true\n",
        "    reference-location: margin\n",
        "include-in-header:\n",
        "  text: |\n",
        "    <style>\n",
        "    .cell-output-stdout {\n",
        "      overflow-y: scroll;\n",
        "      max-height: 300px;\n",
        "    }\n",
        "    </style>\n",
        "title-block-banner: false\n",
        "title-block-style: none\n",
        "execute:\n",
        "  echo: true  \n",
        "  #cache: true\n",
        "  #freeze: true\n",
        "---\n",
        "\n",
        "\n",
        "DSPy has quite a reputation for its automatic prompt optimization capability. Despite that, DSPy is relatively hard to use to optimize a system prompt. DSPy is the implementation of a new Paradigm (one where you do not write prompt you rather focus on your program ), so it does not focus on optimizing a prompt but it rather focus on optimizing a program. Although, I very strongly recommend that you learn DSPy's signature, AI programming and the Intent-Oriented Pragramming paradigm DSPy, sometimes you just want a better system prompt. \n",
        "\n",
        "In this tutorial, I will show you how to optimize as system prompt given a trainset set. The system prompt will be rewritten automatically by an LLM in a loop for several steps.\n",
        "\n",
        "## The task\n",
        "\n",
        "All throughout this tutorial our task will be to make an english to french translator. We will do several optimization and will evolve that task as we progress through that tutorial, but it will always be variants of that.\n",
        "\n",
        "## Optimizing a non existent system prompt\n",
        "\n",
        "As a first task, we will start with an empty system prompt and we will have dspy's optimizer deduce the system prompt based on the training set\n",
        "\n",
        "::: {.callout-tip collapse=\"true\"}\n",
        "## Setting up\n",
        "\n",
        "For this tutorial, you will only need to install dspy and setup a LLM connections. I will be using several LLMs to demonstrate how easy it is to switch between them and show the student/teacher concept. You can however set only one up if you want. If you use a locally hosted model, (you can!) simply skip the setting up of the API key. .\n",
        "\n",
        "For this tutorial, I have will use Kimi-K2 hosted by Groq [Click here to get a groq api key](https://console.groq.com/keys) and Llama models from OpenRouter [Click here to get a OpenRouter key](https://openrouter.ai/settings/keys).\n",
        "\n",
        "::: {.callout-note icon=false appearance=\"simple\" collapse=\"true\"}\n",
        "## python library requirements\n",
        "I like to use uv to install my libraries.\n"
      ],
      "id": "e4faebdc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: false\n",
        "#| code-fold: false\n",
        "#| code-summary: \"\"\n",
        "!uv pip install dspy"
      ],
      "id": "5fdc3bff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.callout-note icon=false appearance=\"simple\" collapse=\"true\"}\n",
        "## api key setup\n",
        "I generally setup my key permanently but you can also do this to set it up just for here and now.\n",
        "\n",
        "```{{python}}\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"[REDACTED]\"\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = \"[REDACTED]\"\n",
        "```\n",
        "\n",
        "::: {.callout-note icon=false appearance=\"simple\" collapse=\"true\"}\n",
        "## Make GROQ_API_KEY permanent\n",
        "\n",
        "Replace GROQ_API_KEY with OPENROUTER_API_KEY to set openrouter key permanently on your system.\n",
        "\n",
        "###### Linux / macOS\n",
        "Append to your shell start-up file (pick the one you actually use):\n",
        "\n",
        "```bash\n",
        "echo \"export GROQ_API_KEY='gsk_[REDACTED]'\" >> ~/.bashrc\n",
        "# or ~/.zshrc, ~/.profile, etc.\n",
        "source ~/.bashrc   # reload once\n",
        "```\n",
        "\n",
        "###### Windows – CMD\n",
        "```cmd\n",
        "setx GROQ_API_KEY \"gsk_[REDACTED]\"\n",
        "```\n",
        "Close and reopen the terminal.\n",
        "\n",
        "###### Windows – PowerShell\n",
        "```powershell\n",
        "[Environment]::SetEnvironmentVariable(\"GROQ_API_KEY\", \"gsk_[REDACTED]\", \"User\")\n",
        "```\n",
        "Refresh with `refreshenv` or open a new window.\n",
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "Usually the first thing to do whenever you work with dspy is to first configure you llm connection.\n"
      ],
      "id": "23f800d1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dspy\n",
        "\n",
        "kimi = dspy.LM(\"groq/moonshotai/kimi-k2-instruct\")\n",
        "dspy.configure(lm = kimi)"
      ],
      "id": "d33d21b2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are new, to dspy. Kimi can now be call just like that:\n"
      ],
      "id": "7c03a254"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "kimi(\"Hello\")"
      ],
      "id": "2cfd5cfb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Although, convenient. This is never really used, when you are using DSPy according to it's paradigm, in DSPy you would be using and calling a program instead. More like that:\n"
      ],
      "id": "8b2bbbb9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class signature(dspy.Signature):\n",
        "    \"\"\"\n",
        "    You are a Pirate\n",
        "    \"\"\"\n",
        "    prompt = dspy.InputField()\n",
        "    generation = dspy.OutputField()\n",
        "\n",
        "my_program = dspy.Predict(signature) \n",
        "\n",
        "my_program(prompt = \"Hello :)\")"
      ],
      "id": "e12d045b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is out of scope to explain all about predict and signatures here as my goal is to simply get you to do automatic system prompt optimization. So let's now focus on that. For optimization we need a training set. DSPy expects the training set to be a list of Example dspy object so we will create our training set like that:\n"
      ],
      "id": "e73ca928"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "examples = [\n",
        "    dspy.Example(prompt=\"I'm going to the convenience store.\", generation=\"Je m'en vais au dépanneur.\"),\n",
        "    dspy.Example(prompt=\"It's really cold out today.\", generation=\"Il fait frette en maudit aujourd'hui.\"),\n",
        "    dspy.Example(prompt=\"Can you help me move this weekend?\", generation=\"Tu peux m'aider à déménager ce weekend?\"),\n",
        "    dspy.Example(prompt=\"We were stuck in traffic for two hours.\", generation=\"On était pognés dans le trafic pendant deux heures.\"),\n",
        "    dspy.Example(prompt=\"She's my girlfriend.\", generation=\"C'est ma blonde.\"),\n",
        "    dspy.Example(prompt=\"That car is so cool!\", generation=\"C'est ben l'fun ce char-là!\"),\n",
        "    dspy.Example(prompt=\"I'll call you tonight.\", generation=\"Je vais t'appeler ce soir.\"),\n",
        "    dspy.Example(prompt=\"He's always bragging.\", generation=\"Il se vente tout l'temps.\"),\n",
        "    dspy.Example(prompt=\"We grabbed a coffee at Tim's.\", generation=\"On a pris un café au Tim.\"),\n",
        "    dspy.Example(prompt=\"Close the window, it's chilly.\", generation=\"Ferme la fenêtre, y fait frette.\"),\n",
        "    dspy.Example(prompt=\"I have an appointment at 3.\", generation=\"J'ai un rendez-vous à trois heures.\"),\n",
        "    dspy.Example(prompt=\"They're celebrating their birthday.\", generation=\"Ils fêtent leur fête.\"),\n",
        "    dspy.Example(prompt=\"I parked in the back.\", generation=\"J'ai stationné dans l'fond.\"),\n",
        "    dspy.Example(prompt=\"The metro is packed.\", generation=\"Le métro est plein à craquer.\"),\n",
        "    dspy.Example(prompt=\"We watched a movie last night.\", generation=\"On a écouté un film hier soir.\"),\n",
        "    dspy.Example(prompt=\"I need to do my groceries.\", generation=\"J'dois faire mon épicerie.\"),\n",
        "    dspy.Example(prompt=\"Don't forget your boots.\", generation=\"Oublie pas tes bottes.\"),\n",
        "    dspy.Example(prompt=\"It's snowing again.\", generation=\"Il neige encore.\"),\n",
        "    dspy.Example(prompt=\"I'll take the bus.\", generation=\"J'va prendre l'bus.\"),\n",
        "    dspy.Example(prompt=\"We're out of milk.\", generation=\"On est à court de lait.\"),\n",
        "]\n",
        "trainset = [x.with_inputs('prompt') for x in examples]"
      ],
      "id": "2ae4dea7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here the task\n"
      ],
      "id": "de7e75ba"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def format_demos(demos):\n",
        "    \"\"\"\n",
        "    Wrap every demo once – no duplicated header lines.\n",
        "    \"\"\"\n",
        "    parts = [\"Here are examples of your expected behavior.\",\n",
        "             \"<examples>\"]\n",
        "    for i, demo in enumerate(demos, 1):\n",
        "        parts += [\n",
        "            f\"<example_{i}>\",\n",
        "            \"User:\",\n",
        "            demo[\"prompt\"],\n",
        "            \"Assistant:\",\n",
        "            demo[\"generation\"],\n",
        "            f\"</example_{i}>\",\n",
        "        ]\n",
        "    parts.append(\"</examples>\")\n",
        "    return \"\\n\".join(parts)"
      ],
      "id": "719fd996",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define the SimplestAdapter as before\n",
        "class SimplestAdapter(dspy.Adapter):\n",
        "    def __call__(self, lm, lm_kwargs, signature, demos, inputs):\n",
        "        print(inputs)\n",
        "        system_content = signature.instructions\n",
        "        if demos:\n",
        "            system_content += \"\\n\" + format_demos(demos)\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_content},\n",
        "            {\"role\": \"user\", \"content\": inputs[\"prompt\"]},\n",
        "        ]\n",
        "        outputs = lm(messages=messages, **lm_kwargs)\n",
        "        return [{\"generation\": outputs[0]}]\n",
        "\n",
        "# Do NOT call dspy.configure(adapter=SimplestAdapter())\n",
        "\n",
        "# Subclass Predict to use the custom adapter only for this instance\n",
        "class MyPredict(dspy.Predict):\n",
        "    def forward(self, **kwargs):\n",
        "        adapter = SimplestAdapter()\n",
        "        with dspy.settings.context(adapter=adapter):\n",
        "            return super().forward(**kwargs)\n",
        "\n",
        "# Use MyPredict instead of dspy.Predict\n",
        "class signature(dspy.Signature):\n",
        "    prompt = dspy.InputField()\n",
        "    generation = dspy.OutputField()\n",
        "\n",
        "system_prompt = \" \"\n",
        "my_program = MyPredict(signature.with_instructions(system_prompt))\n",
        "\n",
        "# Test\n",
        "my_program(prompt=\"Hi how are you?\")"
      ],
      "id": "ae36fd8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import re\n",
        "\n",
        "def is_french(text):\n",
        "    # Naive French detector: check for common French words/accents\n",
        "    french_markers = [\n",
        "        r\"\\b(le|la|les|un|une|des|du|de|et|à|est|sont|avec|pour|sur|par|mais|ou|où|que|qui|quand|comment|nous|vous|ils|elles|ça|ce|cette|ces)\\b\",\n",
        "        r\"[éèêàùçîôâœëïü]\",\n",
        "    ]\n",
        "    return any(re.search(marker, text.lower()) for marker in french_markers)\n",
        "\n",
        "def translation_judge(example, prediction, trace=None):\n",
        "    \"\"\"\n",
        "    Return 1.0 if the output looks French, else 0.0.\n",
        "    Doing the cast explicitly guarantees we never hand DSPy a None.\n",
        "    \"\"\"\n",
        "    output = prediction.get(\"generation\", \"\") or \"\"\n",
        "    try:\n",
        "        return float(is_french(output))\n",
        "    except Exception:\n",
        "        # Anything weird is just a miss\n",
        "        return 0.0"
      ],
      "id": "713b8544",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "optimizer = dspy.MIPROv2(translation_judge, max_bootstrapped_demos = 0, max_labeled_demos = 0)\n",
        "my_program_optimized = optimizer.compile(my_program, trainset=trainset)"
      ],
      "id": "7cadd95e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_program_optimized(prompt = \"Hi how are you?\")"
      ],
      "id": "f2e607f6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_program_optimized.inspect_history()"
      ],
      "id": "adda5f2c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "optimizer = dspy.MIPROv2(translation_judge)\n",
        "my_program_optimized = optimizer.compile(my_program, trainset=trainset)"
      ],
      "id": "49e612a9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_program_optimized(prompt = \"Hi how are you?\")"
      ],
      "id": "178c9422",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_program_optimized.inspect_history()"
      ],
      "id": "0b1900cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "optimizer = dspy.SIMBA(metric = translation_judge, bsize = 8)\n",
        "my_program_optimized = optimizer.compile(my_program, trainset=trainset)"
      ],
      "id": "140c8352",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_program_optimized(prompt = \"Hi how are you?\")"
      ],
      "id": "5c489628",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_program_optimized.inspect_history()"
      ],
      "id": "6acf54d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "evaluator = dspy.Evaluate(devset = trainset, metric=translation_judge)\n",
        "evaluator(my_program_optimized)"
      ],
      "id": "5ee42b52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "evaluator = dspy.Evaluate(devset = trainset, metric=translation_judge)\n",
        "evaluator(my_program)"
      ],
      "id": "afbecbc6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "optimizer = dspy.MIPROv2(translation_judge, max_bootstrapped_demos = 2, max_labeled_demos = 2)\n",
        "my_program_optimized_with_demo = optimizer.compile(my_program, trainset=trainset)"
      ],
      "id": "1348c567",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_program_optimized_with_demo(prompt = \"Hi how are you?\")"
      ],
      "id": "f8584648",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_program_optimized_with_demo.inspect_history()"
      ],
      "id": "476ecb4e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "optimizer = dspy.BootstrapFewShotWithOptuna(translation_judge, max_bootstrapped_demos = 10, max_labeled_demos = 10, max = 3)\n",
        "my_program_optimized_with_demo = optimizer.compile(my_program, trainset=trainset, max_demos=3)"
      ],
      "id": "764b4b9f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_program_optimized_with_demo(prompt = \"Hi how are you today?\")"
      ],
      "id": "4e9e0d65",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_program_optimized_with_demo.inspect_history()"
      ],
      "id": "c59d58b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class QuebecTranslationJudge(dspy.Signature):\n",
        "    \"\"\"You are an expert Quebec French linguist. For each English sentence and its proposed French translation, evaluate the translation on a scale of 1 to 5 based on the following criteria, with 5 being a perfect, natural-sounding translation.\n",
        "\n",
        "1.  **Accuracy**: Does the French convey the same meaning as the English?\n",
        "2.  **Register**: Is the tone appropriately informal/colloquial (not formal textbook French)?\n",
        "3.  **Regional Vocabulary**: Does it use authentic Quebec French terms (e.g., \"dépanneur\", \"frette\", \"char\")?\n",
        "4.  **Contractions**: Are natural Quebec French contractions used (e.g., \"j'va\", \"t'sais\", \"y fait\")?\n",
        "5.  **Proper Nouns & Anglicisms**: Are names (e.g., \"Tim's\") and common anglicisms (e.g., \"weekend\") handled appropriately for Quebec French?\n",
        "\n",
        "Provide brief feedback on any issues and output only the final numerical score.\n",
        "\n",
        "IMPORTANT IF MEANING IS CHANGED SET TO 0.\n",
        "\"\"\"\n",
        "\n",
        "    english_sentence = dspy.InputField(desc=\"The original sentence in English.\")\n",
        "    french_translation = dspy.InputField(desc=\"The proposed translation in Quebec French.\")\n",
        "    feedback = dspy.OutputField(desc=\"Brief feedback on the translation's quality.\")\n",
        "    score = dspy.OutputField(desc=\"A single integer from 1 to 5.\")\n",
        "\n",
        "# If you have a capable model configured globally, just do this:\n",
        "llm_judge = dspy.Predict(QuebecTranslationJudge)\n",
        "\n",
        "def translation_judge(example, prediction, trace=None):\n",
        "    \"\"\"\n",
        "    An LLM-based metric that judges translation quality.\n",
        "    It robustly parses the score and normalizes it to a 0.0-1.0 scale.\n",
        "    \"\"\"\n",
        "    english_sentence = example.prompt\n",
        "    # Ensure the prediction's output is not empty\n",
        "    french_translation = prediction.get(\"generation\", \"\")\n",
        "    if not french_translation:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        # Call the LLM judge to get a score\n",
        "        result = llm_judge(\n",
        "            english_sentence=english_sentence,\n",
        "            french_translation=french_translation\n",
        "        )\n",
        "        # Parse the score and normalize it to a 0.0-1.0 range\n",
        "        # (e.g., a score of 5 becomes 1.0, 1 becomes 0.2)\n",
        "        score = float(result.score)\n",
        "        return score / 5.0\n",
        "    except (ValueError, AttributeError, TypeError):\n",
        "        # If the LLM fails to output a valid score, return 0.0\n",
        "        return 0.0"
      ],
      "id": "a21456cb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "optimizer = dspy.BootstrapFewShotWithOptuna(translation_judge, max_bootstrapped_demos = 10, max_labeled_demos = 10, max_rounds = 3)\n",
        "my_program_optimized_with_demo2 = optimizer.compile(my_program, trainset=trainset, max_demos=3)"
      ],
      "id": "8edd6032",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_program_optimized_with_demo2(prompt = \"Hi how are you today?\")"
      ],
      "id": "a2281822",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_program_optimized_with_demo2.inspect_history()"
      ],
      "id": "4d1d6339",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "maximerivest-blog",
      "language": "python",
      "display_name": "Python (maximerivest-blog)",
      "path": "/home/maxime/.local/share/jupyter/kernels/maximerivest-blog"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}