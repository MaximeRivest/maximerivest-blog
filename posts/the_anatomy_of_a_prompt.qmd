---
title: "The anatomy of a prompt [wip]"
date: "2025-07-06"
---

My criteria for a good AI programing interface:

## Pointing to models should be at most a url, and a model name

I must be able to change model, provider, inference engine as easily as I would say it to a competent Applied AI engineer: "Use 'meta-llama/Llama-3.1-8B' on groq" or "Use Claude Sonnet 3.6 on Bedrock" or "Use 'meta-llama/Llama-3.1-8B' with vllm".

Things everything should always work without exception when I can url and provider except for cases where modalities are not supported. If it's not a vision capable model it will obviously not take in images.

##

Prompt was a particularly correct term chosen to describe the action of writing llm input to make a response happen. I wonder who said it first and what else was 'tried'.

Prompting

Definition: "the act of trying to make someone say something"

Example: Kids of that age really shouldn't need prompting to say thank you for things.

Prompt

Definition: "to make something happen"

Example: The bishop's speech has prompted an angry response from both political parties.

but I like that api. Before learning about dspy I was happy with no other interface and I was working on my own (https://github.com/MaximeRivest/onetokenpy-library). I have not yet felt I needed to continue my work in parallel in onetokenpy, I think the few things that were lacking for me, I can contribute to dspy. If you 'accept' that I use dspy because it's the simplest abstraction, then 'adoption' all other abstraction, optionally, and when useful just make total sense. So there is no concept of 'migration' for me it's rather one of addition. I use the off the shell simple caller when enough. The off the shell simple ChatAdapter when I want more. The off the shell simple optimizer when I want that. My own adapter if I want more, my own optimizer if I want more.
