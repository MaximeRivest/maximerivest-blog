{
  "hash": "c7449e23cbb400e615a03abba374a02b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"A Simple Introduction to DSPy\"\ndate: 2025-06-03\nauthor: Maxime Rivest\ndescription: \"\"\ndraft: false\nformat:\n  html:\n    toc: true\n    toc-location: right\ntitle-block-banner: false\ntitle-block-style: none\nexecute:\n  cache: true\n  freeze: true\n---\n\n\n![](/posts/dspy-banner.jpeg)\n\nDSPy is simple and powerful. It is the best way to build LLM software right now. Despite that, lots of people keep putting off learning it. I know I did—for a whole year! I was excited about DSPy, but I thought I would need a substantial time investment before I could \"get it.\" That’s not the case! It took me one hour. If you know Python, in an hour you’ll either have built several LLM programs, or you’ll have built one, benchmarked it, and optimized it!\n\nIn this article, we’ll go through the entire cycle: building a program, creating a gold set (synthetically, with AI—and yes, it’s actually useful, not just contrived!), and evaluating the results.\n\nFor this article, our task will be to build a program that can count the mentions of “Artificial Intelligence,” “AI,” or any other ways of referring to AI.\n\n## Overview\n\nWe'll:\n\n1. Define a DSPy signature for counting AI mentions\n2. Fetch data from Wikipedia\n3. Create a training dataset using a stronger model (Claude Sonnet 4)\n4. Optimize a weaker model (Gemini Flash-lite 2.0) to match the stronger model's performance\n\n\n::: {#fig-cern}\n\n\n{{< video https://youtu.be/fXjCleTYUm8?si=qA6mF6tccVDkOeez >}}\n\n\nA video version of this tutorial, even more beginner friendly.\n\n:::\n\n\n\n## Step 1: Define the AI Task Signature\n\nIn DSPy, we define the task using a Signature class instead of writing prompts manually. DSPy provides two ways for you to specify your program. This is the shortest method. In this case, it has four parts:\n\n- **dspy.Predict**: This could have been `dspy.ChainOfThought`; it lets you specify the \"strategy\" the LLM should use. Predict is the vanilla option—no special strategy is mentioned in the prompt that DSPy sends to the LLM.\n- **Input (\"paragraph\")**: This tells the LLM that it will receive a \"paragraph\" as input.\n- **Output (\"ai_occurrences_count\")**: This tells the LLM that it will have to output the \"AI occurrences count.\"\n- **Output Type (\"float\")**: This specifies that the output should be a float—nothing else.\n\n::: {#830a9c91 .cell execution_count=2}\n``` {.python .cell-code}\nimport dspy\n```\n:::\n\n\n::: {#80ffdbd1 .cell execution_count=3}\n``` {.python .cell-code}\nai_counter = dspy.Predict(\"paragraph -> ai_occurrences_count: float\")\n```\n:::\n\n\nYou can specify more. To fully define your program, you would use the class syntax (see the chunk below). In this case, you can add general instructions and descriptions to the fields (inputs and/or outputs).\n\n::: {#980af8d0 .cell execution_count=4}\n``` {.python .cell-code}\nimport dspy\n\n# Setup the llm\ndspy.configure(lm=dspy.LM('gemini/gemini-2.0-flash-lite', temperature = 1.0, max_tokens = 6000))\n\n# This define the signature of the AI function. The replaces prompts.\nclass count_ai_occurrences(dspy.Signature):\n    \"\"\"Count the number times the word 'Artificial Intelligence'\n    or 'AI' or any other reference to AI or AI-related terms appears in the paragraph\"\"\"\n    paragraph: str= dspy.InputField(desc = \"The paragraph to count the AI mentions in\")\n    ai_occurrences_count: int= dspy.OutputField(desc = \"The number of times the word 'Artificial Intelligence' or 'AI' appears in the paragraph\")\n\ndspy_module = dspy.Predict(count_ai_occurrences)\n```\n:::\n\n\nThis signature will be turned into the following prompt by DSPy:\n\n---\n\n```json\n[\n  {\n    \"role\": \"system\",\n    \"content\": \"\"\"Your input fields are:\n  1. `paragraph` (str): The paragraph to count the AI mentions in\n\nYour output fields are:\n  1. `ai_occurrences_count` (int): Number of times 'Artificial Intelligence'\n     or 'AI' appears in the paragraph\n\nFormat all interactions like this, filling in the values:\n\n[[ ## paragraph ## ]]\n{paragraph}\n\n[[ ## ai_occurrences_count ## ]]\n{ai_occurrences_count}   # must be a single int value\n\n[[ ## completed ## ]]\n\nObjective:\n  Count the number times the word 'Artificial Intelligence'\n    or 'AI' or any other reference to AI or AI-related terms appears in the paragraph.\"\"\"\n  },\n  {\n    \"role\": \"user\",\n    \"content\": \"\"\"[[ ## paragraph ## ]]\nThis is a paragraph mentioning AI once.\n\nRespond with the corresponding output fields, starting with\n[[ ## ai_occurrences_count ## ]] (must be a valid Python int),\nthen end with [[ ## completed ## ]].\n\"\"\"\n  }\n]\n```\n\n---\n\n\nOk, so our program is defined! That's it.\n\nThere's one small thing I like to do—it's entirely optional. I do it because I want to use my DSPy program more like a regular function. So, before I go ahead, I wrap it in a function:\n\n```python\ndef count_ai_occurrences_f(paragraph):\n    return dspy_module(paragraph=paragraph).ai_occurrences_count\n```\n\nThe DSPy module requires keyword arguments and returns output as an object. Instead of repeatedly specifying my keyword arguments and the single output I want, I bake that in here. This also has the added benefit that my function now composes well with my data analytics tools, which expect not to provide a keyword argument or extract a value from an output object.\n\n## Step 2: Fetch Data\n\nThis section has nothing to do with LLMs. We are simply fetching content from the Wikipedia AI page and storing it in a dataframe. We use the Attachments library to easily fetch and split paragraphs from Wikipedia.\n\n```python\nfrom attachments import Attachments\n\nattachments_dsl = \"[images: false][select: p,title,h1,h2,h3,h4,h5,h6][split: paragraphs]\"\na = Attachments(\"https://en.wikipedia.org/wiki/Artificial_intelligence\" + attachments_dsl)\n```\n\nWe then use Datar as our data manipulation tool. I come from R and I love dplyr. Datar is an effort to provide a similar data manipulation experience here in Python.\n\n```python\nfrom datar import f\nimport datar.base as b\nfrom datar.tibble import tibble\nfrom datar.dplyr import mutate, summarise, n\n\ndf = tibble(paragraphs = [p.text for p in a[:10]])\n```\n\n::: {.callout-note}\n## Dataframe Structure\nThe resulting tibble dataframe contains only one column (`paragraphs`) with the text from Wikipedia.\n:::\n\n![](/posts/dfimage1.jpg)\n\n## Step 3: Applying the AI to our paragraphs\n\nNow we are starting to use large language models. Below, we apply our function to every row in our dataframe. In other words, we loop through each paragraph and send it to the LLM. The LLM returns the number of times it thinks \"AI\" was mentioned in the paragraph. The result from the LLM is extracted as a float. We store this in a new column of our dataframe, which we name `flash_response`.\n\n```python\ndf = mutate(df, flash_response = f.paragraphs.apply(count_ai_occurrences_f))\n```\n\nThis column is now our baseline. This shows how Flash-lite performs with the base prompt from DSPy. Now, we want to optimize that prompt! For this, we need a gold set.\n\nI like to create gold sets with state-of-the-art (SOTA) models and then optimize the prompt to approximate the responses I would get from a SOTA model, but using a much smaller, faster, and cheaper model. In other words, we'll provide a sample of our paragraphs to Sonnet 4 and then automatically \"find a way\" to prompt Flash-lite into responding like Sonnet would. This is extremely useful when you don't know the answer yourself but know that SOTA models do—or at least they get it \"right enough\" for you to gain valuable insights.\n\nOk, so now we want to add a column with Sonnet's answers.\n\n```python\nwith dspy.context(lm=dspy.LM('anthropic/claude-sonnet-4-20250514')):\n    df_with_goldset_col = mutate(df, resp_sonnet = f.paragraphs.apply(count_ai_occurrences_f))\n```\n\nThat's it. Let's break down those two lines. First, DSPy recommends using either `dspy.context` or `dspy.configure` to set the LLM. Both ways are fine and both are thread-safe. On the second line, we take our current dataframe, which now has two columns (`paragraphs` and `flash_response`), and loop through every value in paragraphs, passing each one to our AI program. We then save all of that in a new column called `resp_sonnet`, and the entire dataframe is stored as `df_with_goldset_col`.\n\n::: {.callout-tip}\n## Gold Set Strategy\nUsing a SOTA model to create gold sets is a practical approach when you don't have manually labeled data but trust that advanced models will perform well enough for your use case.\n:::\n\n![](/posts/dfimage2.png)\n\n## Evaluation\n\nNext, we need a metric! In this case, we'll keep it simple—we'll require an exact match. Let's add a column for exact_match (true/false).\n\n```python\ndf_with_goldset_col = mutate(df_with_goldset_col, exact_match = f.resp_sonnet == f.flash_response)\n```\n![](/posts/dfimage3.png)\n\nLet's quickly calculate our current precision. Here, we are purely in dataframe manipulation mode with Datar. Using the `>>` operator, we can pass the dataframe you see above (as it comes out of mutate) to the summarise function, which sums all the True values (1s) and divides by the number of rows.\n\n```python\nbaseline_metrics = (mutate(df_with_goldset_col, exact_match = f.resp_sonnet == f.flash_response) >>\n    summarise(baseline_precision = b.sum(f.exact_match)/n() * 100))\n```\n\nThis tells us that we have **65% baseline precision** with Flash-lite and this prompt.\n\n## Preparing for the optimizer\n\nSo now we have all the conceptual pieces needed to run the optimizer.\n\n```python\noptimizer = dspy.MIPROv2(metric=exact_match)\noptimized_dspy_module = optimizer.compile(dspy_module, trainset=trainset)\n```\n\nBut notice how I said \"conceptual\"—now we need to do a bit of data wrangling to get our dataframe into an object that compile knows how to work with. The same goes for the metric.\n\nHere's how to reshape the data:\n\n```python\ntrainset = []\nfor r in df_with_goldset_col.to_dict(orient='records'):\n    trainset.append(dspy.Example(\n        paragraph=r['paragraphs'],                    # this is the input\n        ai_occurrences_count=r[\"resp_sonnet\"]).       # this is the target\n       with_inputs('paragraph'))                      # this is needed (not sure why)\n```\n\nThis is how to prepare the metric: it has to use `.[output_name]` to access the value of x (gold set) and y (trained model output).\n\n```python\ndef exact_match(x, y, trace=None):\n    return x.ai_occurrences_count == y.ai_occurrences_count\n```\n\nWith these two chunks of code, the optimizer will run! In this case, if we were to keep it as is, we would be using Flash-lite to compose the prompts (whenever the optimizer we choose does that). I prefer to use a SOTA model for that, so we will set a teacher model. To set a teacher model on MIPROv2, use the `teacher_settings` keyword. Be careful—different optimizers set the teacher in different ways.\n\n## Automatic prompt optimization\n\n```python\noptimizer = dspy.MIPROv2(metric=exact_match,\n                        teacher_settings=dspy.LM('anthropic/claude-sonnet-4-20250514'))\noptimized_dspy_module = optimizer.compile(dspy_module, trainset=trainset)\n```\n\nWe'll wrap it in a function again so we can use it with our data analytics tools.\n\n```python\ndef count_ai_occurrences_opt(paragraph):\n    return optimized_dspy_module(paragraph=paragraph).ai_occurrences_count\n```\n\nAnd we've built a complete one-shot pipeline to apply the optimized program, add it as a new column, and summarize the dataframe into performance metrics. Apart from `count_ai_occurrences_opt`, this has nothing to do with DSPy.\n\n```python\nfinal_performance = (df_with_goldset_col >>\n    mutate(\n        # Applies flash to every row with the optimized prompt\n        resp_flash_opt= f.paragraphs.apply(count_ai_occurrences_opt)) >>\n    mutate(\n        # Add 2 columns with 0 or 1 if the flash response is equal to the sonnet response\n        flash_eq_sonnet = f.resp_sonnet == f.flash_response,  # Compare flash with sonnet\n        flash_opt_eq_sonnet = f.resp_flash_opt == f.resp_sonnet  # Compare opt flash with sonnet\n        ) >>\n    summarise(\n        # Sum the number of rows where the flash response is equal to the sonnet response\n        flashlight_before_opt = b.sum(f.flash_eq_sonnet)/n() * 100, #n() is the number of rows in df\n        # Sum the number of rows where the opt flash response is equal to the sonnet response\n        flashlight_after_opt = b.sum(f.flash_opt_eq_sonnet)/n() * 100 #n() is the number of rows in df\n    ) >>\n    mutate(precision_increase=f.flashlight_after_opt-f.flashlight_before_opt)\n    )\n```\n\n![](/posts/dfimage4.png)\n\n## Results\n\n::: {.callout-important}\n## Performance Improvement\nFlash-lite improved by **20%**. Not bad!\n:::\n\nHere is the optimized prompt:\n\n```json\n[\n  {\n    \"role\": \"system\",\n    \"content\": \"\"\"Your input fields are:\n  1. `paragraph` (str): The paragraph to count the AI mentions in\n\nYour output fields are:\n  1. `ai_occurrences_count` (int): The number of times the word 'Artificial Intelligence'\n     or 'AI' appears in the paragraph\n\nAll interactions will be structured in the following way, with the appropriate values filled in:\n\n[[ ## paragraph ## ]]\n{paragraph}\n\n[[ ## ai_occurrences_count ## ]]\n{ai_occurrences_count}   # note: the value you produce must be a single int value\n\n[[ ## completed ## ]]\n\nObjective:\n  Analyze the provided paragraph and determine the frequency of mentions related to\n  \"Artificial Intelligence\" (AI). This includes direct references to \"AI\",\n  \"Artificial Intelligence\", as well as any related concepts, technologies, or subfields\n  associated with AI. Provide a count representing the total number of AI-related mentions.\n\"\"\"\n  },\n  {\n    \"role\": \"user\",\n    \"content\": \"\"\"[[ ## paragraph ## ]]\nIn classical planning, the agent knows exactly what the effect of any action\nwill be.[35] In most real-world problems, however, the agent may not be certain\nabout the situation they are in (it is \"unknown\" or \"unobservable\") and it may\nnot know for certain what will happen after each possible action (it is not\n\"deterministic\"). It must choose an action by making a probabilistic guess and\nthen reassess the situation to see if the action worked.[36]\n\nRespond with the corresponding output fields, starting with the field\n[[ ## ai_occurrences_count ## ]] (must be formatted as a valid Python int), and\nthen ending with the marker for [[ ## completed ## ]].\n\"\"\"\n  }\n]\n```\n\n## Conclusion\n\nIn about 50 lines, we:\n- Fetched paragraphs from Wikipedia\n- Created a gold-set\n- Tuned Flash-lite\n- Improved its precision by 20%\n\nNo prompt spaghetti.\n\n## The Complete Script\n\n```python\nimport dspy\nfrom attachments import Attachments\nfrom datar import f\nimport datar.base as b\nfrom datar.tibble import tibble\nfrom datar.dplyr import mutate, summarise, n\n\n# Setup the LLM\ndspy.configure(lm=dspy.LM('gemini/gemini-2.0-flash-lite', temperature=1.0, max_tokens=6000))\n\n# Define the signature\nclass count_ai_occurrences(dspy.Signature):\n    \"\"\"Count the number times the word 'Artificial Intelligence'\n    or 'AI' or any other reference to AI or AI-related terms appears in the paragraph\"\"\"\n    paragraph: str = dspy.InputField(desc=\"The paragraph to count the AI mentions in\")\n    ai_occurrences_count: int = dspy.OutputField(desc=\"The number of times the word 'Artificial Intelligence' or 'AI' appears in the paragraph\")\n\n# Create the DSPy module\ndspy_module = dspy.Predict(count_ai_occurrences)\n\n# Wrap in a function\ndef count_ai_occurrences_f(paragraph):\n    return dspy_module(paragraph=paragraph).ai_occurrences_count\n\n# Fetch data\nattachments_dsl = \"[images: false][select: p,title,h1,h2,h3,h4,h5,h6][split: paragraphs]\"\na = Attachments(\"https://en.wikipedia.org/wiki/Artificial_intelligence\" + attachments_dsl)\n\n# Create dataframe\ndf = tibble(paragraphs=[p.text for p in a[:10]])\n\n# Apply baseline model\ndf = mutate(df, flash_response=f.paragraphs.apply(count_ai_occurrences_f))\n\n# Create gold set with Sonnet\nwith dspy.context(lm=dspy.LM('anthropic/claude-sonnet-4-20250514')):\n    df_with_goldset_col = mutate(df, resp_sonnet=f.paragraphs.apply(count_ai_occurrences_f))\n\n# Calculate baseline precision\nbaseline_metrics = (mutate(df_with_goldset_col, exact_match=f.resp_sonnet == f.flash_response) >>\n    summarise(baseline_precision=b.sum(f.exact_match)/n() * 100))\n\n# Prepare training set\ntrainset = []\nfor r in df_with_goldset_col.to_dict(orient='records'):\n    trainset.append(dspy.Example(\n        paragraph=r['paragraphs'],\n        ai_occurrences_count=r[\"resp_sonnet\"]).with_inputs('paragraph'))\n\n# Define metric\ndef exact_match(x, y, trace=None):\n    return x.ai_occurrences_count == y.ai_occurrences_count\n\n# Optimize\noptimizer = dspy.MIPROv2(metric=exact_match,\n                        teacher_settings=dspy.LM('anthropic/claude-sonnet-4-20250514'))\noptimized_dspy_module = optimizer.compile(dspy_module, trainset=trainset)\n\n# Wrap optimized module\ndef count_ai_occurrences_opt(paragraph):\n    return optimized_dspy_module(paragraph=paragraph).ai_occurrences_count\n\n# Calculate final performance\nfinal_performance = (df_with_goldset_col >>\n    mutate(resp_flash_opt=f.paragraphs.apply(count_ai_occurrences_opt)) >>\n    mutate(\n        flash_eq_sonnet=f.resp_sonnet == f.flash_response,\n        flash_opt_eq_sonnet=f.resp_flash_opt == f.resp_sonnet\n    ) >>\n    summarise(\n        flashlight_before_opt=b.sum(f.flash_eq_sonnet)/n() * 100,\n        flashlight_after_opt=b.sum(f.flash_opt_eq_sonnet)/n() * 100\n    ) >>\n    mutate(precision_increase=f.flashlight_after_opt-f.flashlight_before_opt)\n)\n```\n\n<style>\n/* Zen DSPy Theme - Minimal and Clean */\n\n/* Hero image styling */\narticle > p:first-of-type img {\n  width: 100%;\n  height: 320px;\n  object-fit: cover;\n  object-position: center;\n  margin: 0 0 3rem 0;\n  border-radius: 0;\n}\n\n/* Clean title */\n.title {\n  font-size: 2.5rem;\n  font-weight: 800;\n  letter-spacing: -0.02em;\n  line-height: 1.2;\n  margin: 0 0 1rem 0;\n  color: var(--bs-gray-900);\n}\n\n.quarto-title-meta {\n  font-size: 0.9rem;\n  color: var(--bs-gray-600);\n  margin-bottom: 3rem;\n}\n\n/* Simplified TOC */\n#TOC, nav[role=\"doc-toc\"] {\n  font-size: 0.9rem;\n  line-height: 1.8;\n}\n\n#TOC ul, nav[role=\"doc-toc\"] ul {\n  list-style: none;\n  padding-left: 0;\n}\n\n#TOC li, nav[role=\"doc-toc\"] li {\n  margin: 0.5rem 0;\n}\n\n#TOC a, nav[role=\"doc-toc\"] a {\n  color: var(--bs-gray-600);\n  text-decoration: none;\n  padding: 0.25rem 0;\n  display: block;\n  border-left: 2px solid transparent;\n  padding-left: 1rem;\n  transition: all 0.2s ease;\n}\n\n#TOC a:hover, nav[role=\"doc-toc\"] a:hover {\n  color: var(--bs-primary);\n  border-left-color: var(--bs-primary);\n  background: rgba(12, 133, 204, 0.05);\n}\n\n#TOC a.active, nav[role=\"doc-toc\"] a.active {\n  color: var(--bs-primary);\n  font-weight: 600;\n  border-left-color: var(--bs-primary);\n}\n\n@media (min-width: 992px) {\n  #TOC, nav[role=\"doc-toc\"] {\n    position: sticky;\n    top: 2rem;\n    max-height: calc(100vh - 4rem);\n    overflow-y: auto;\n    margin-left: 3rem;\n  }\n}\n\n/* Clean code blocks */\npre {\n  background: #f8f9fa;\n  border: none;\n  border-radius: 6px;\n  padding: 1.5rem;\n  margin: 1.5rem 0;\n  overflow-x: auto;\n  overflow-y: hidden;\n  font-size: 0.875rem;\n  line-height: 1.6;\n  max-height: none;\n  /* Remove shadow line */\n  box-shadow: none !important;\n  border: 1px solid #e9ecef;\n}\n\npre code {\n  font-family: 'JetBrains Mono', 'Fira Code', monospace;\n  font-size: inherit;\n  white-space: pre;\n  word-break: normal;\n  word-wrap: normal;\n  background: transparent !important;\n  padding: 0 !important;\n  display: inline-block;\n  min-width: 100%;\n}\n\n/* Force syntax highlighting colors */\n.sourceCode {\n  overflow: auto !important;\n}\n\n/* Python syntax highlighting */\n.sourceCode .kw { color: #0969da !important; font-weight: 600; } /* Keywords */\n.sourceCode .dt { color: #0550ae !important; } /* Data types */\n.sourceCode .dv, .sourceCode .fl { color: #0a3069 !important; } /* Numbers */\n.sourceCode .st { color: #032f62 !important; } /* Strings */\n.sourceCode .co { color: #6e7781 !important; font-style: italic; } /* Comments */\n.sourceCode .ot { color: #953800 !important; } /* Other tokens */\n.sourceCode .cf { color: #cf222e !important; font-weight: 600; } /* Control flow */\n.sourceCode .fu { color: #8250df !important; } /* Functions */\n.sourceCode .im { color: #cf222e !important; } /* Import */\n.sourceCode .op { color: #0969da !important; } /* Operators */\n.sourceCode .bu { color: #8250df !important; } /* Built-in */\n.sourceCode .va { color: #0550ae !important; } /* Variables */\n.sourceCode .cn { color: #0a3069 !important; } /* Constants */\n.sourceCode .sc { color: #0a3069 !important; } /* Special chars */\n\n/* Better formatting for JSON/prompt blocks */\npre:has(code.language-python) {\n  font-size: 0.8rem;\n}\n\n/* Clean scrollbar styling */\npre::-webkit-scrollbar {\n  width: 6px;\n  height: 6px;\n}\n\npre::-webkit-scrollbar-track {\n  background: transparent;\n}\n\npre::-webkit-scrollbar-thumb {\n  background: rgba(0, 0, 0, 0.15);\n  border-radius: 3px;\n}\n\npre::-webkit-scrollbar-thumb:hover {\n  background: rgba(0, 0, 0, 0.25);\n}\n\n/* Remove any shadows or borders that might appear on scroll */\npre:focus {\n  outline: none;\n  box-shadow: none !important;\n}\n\ndiv.sourceCode {\n  overflow: auto;\n  background: transparent;\n  border: none;\n  box-shadow: none !important;\n  margin: 0;\n}\n\n/* Inline code */\ncode:not(pre code) {\n  background: rgba(12, 133, 204, 0.1);\n  color: var(--bs-gray-900);\n  padding: 0.2em 0.4em;\n  border-radius: 3px;\n  font-size: 0.875em;\n  font-family: 'JetBrains Mono', monospace;\n}\n\n/* Callouts */\n.callout {\n  border-left: 3px solid var(--bs-primary);\n  padding: 1rem 1.5rem;\n  margin: 1.5rem 0;\n  background: rgba(12, 133, 204, 0.05);\n  border-radius: 0 6px 6px 0;\n}\n\n.callout-note {\n  border-left-color: var(--bs-info);\n  background: rgba(29, 191, 224, 0.05);\n}\n\n.callout-tip {\n  border-left-color: var(--bs-success);\n  background: rgba(29, 211, 1, 0.05);\n}\n\n.callout-important {\n  border-left-color: var(--bs-warning);\n  background: rgba(255, 207, 1, 0.05);\n}\n\n/* Dark mode adjustments */\n.quarto-dark pre {\n  background: #1a1a1a;\n  color: #e2e8f0;\n  border-color: #2d3748;\n}\n\n/* Dark mode syntax highlighting */\n.quarto-dark .sourceCode .kw { color: #79c0ff !important; } /* Keywords */\n.quarto-dark .sourceCode .dt { color: #a5d6ff !important; } /* Data types */\n.quarto-dark .sourceCode .dv, .quarto-dark .sourceCode .fl { color: #79c0ff !important; } /* Numbers */\n.quarto-dark .sourceCode .st { color: #a5d6ff !important; } /* Strings */\n.quarto-dark .sourceCode .co { color: #8b949e !important; } /* Comments */\n.quarto-dark .sourceCode .ot { color: #ffa657 !important; } /* Other tokens */\n.quarto-dark .sourceCode .cf { color: #ff7b72 !important; } /* Control flow */\n.quarto-dark .sourceCode .fu { color: #d2a8ff !important; } /* Functions */\n.quarto-dark .sourceCode .im { color: #ff7b72 !important; } /* Import */\n.quarto-dark .sourceCode .op { color: #79c0ff !important; } /* Operators */\n.quarto-dark .sourceCode .bu { color: #d2a8ff !important; } /* Built-in */\n.quarto-dark .sourceCode .va { color: #7ee787 !important; } /* Variables */\n.quarto-dark .sourceCode .cn { color: #79c0ff !important; } /* Constants */\n.quarto-dark .sourceCode .sc { color: #79c0ff !important; } /* Special chars */\n\n.quarto-dark pre::-webkit-scrollbar-thumb {\n  background: rgba(255, 255, 255, 0.15);\n}\n\n.quarto-dark pre::-webkit-scrollbar-thumb:hover {\n  background: rgba(255, 255, 255, 0.25);\n}\n\n.quarto-dark code:not(pre code) {\n  background: rgba(29, 191, 224, 0.15);\n  color: #e2e8f0;\n}\n\n.quarto-dark .callout {\n  background: rgba(12, 133, 204, 0.1);\n}\n\n.quarto-dark .callout-note {\n  background: rgba(29, 191, 224, 0.1);\n}\n\n.quarto-dark .callout-tip {\n  background: rgba(29, 211, 1, 0.1);\n}\n\n.quarto-dark .callout-important {\n  background: rgba(255, 207, 1, 0.1);\n}\n\n.quarto-dark #TOC a, .quarto-dark nav[role=\"doc-toc\"] a {\n  color: var(--bs-gray-400);\n}\n\n.quarto-dark #TOC a:hover, .quarto-dark nav[role=\"doc-toc\"] a:hover,\n.quarto-dark #TOC a.active, .quarto-dark nav[role=\"doc-toc\"] a.active {\n  color: var(--bs-secondary);\n  border-left-color: var(--bs-secondary);\n  background: rgba(29, 191, 224, 0.1);\n}\n\n/* Content spacing */\narticle {\n  max-width: 45rem;\n  margin: 0 auto;\n  padding: 2rem 1rem;\n}\n\narticle h2 {\n  margin-top: 3rem;\n  margin-bottom: 1.5rem;\n  font-weight: 700;\n  font-size: 1.75rem;\n  letter-spacing: -0.01em;\n}\n\narticle h3 {\n  margin-top: 2rem;\n  margin-bottom: 1rem;\n  font-weight: 600;\n  font-size: 1.25rem;\n}\n\narticle p {\n  line-height: 1.7;\n  margin-bottom: 1.25rem;\n  color: var(--bs-gray-800);\n}\n\narticle ul, article ol {\n  margin: 1.5rem 0;\n  padding-left: 1.5rem;\n}\n\narticle ul li, article ol li {\n  margin-bottom: 0.5rem;\n  line-height: 1.7;\n}\n\n.quarto-dark article p {\n  color: var(--bs-gray-300);\n}\n\n/* Images */\narticle img {\n  max-width: 100%;\n  height: auto;\n  margin: 2rem auto;\n  display: block;\n}\n\n/* Mobile responsiveness */\n@media (max-width: 991px) {\n  /* Typography adjustments */\n  .title {\n    font-size: 1.75rem;\n    line-height: 1.3;\n    margin-bottom: 0.75rem;\n  }\n\n  .quarto-title-meta {\n    font-size: 0.85rem;\n    margin-bottom: 2rem;\n  }\n\n  article {\n    padding: 1rem;\n    max-width: 100%;\n  }\n\n  article h2 {\n    font-size: 1.5rem;\n    margin-top: 2rem;\n    margin-bottom: 1rem;\n  }\n\n  article h3 {\n    font-size: 1.25rem;\n    margin-top: 1.5rem;\n  }\n\n  article p {\n    font-size: 1rem;\n    line-height: 1.6;\n    margin-bottom: 1rem;\n  }\n\n  /* Hero image adjustment */\n  article > p:first-of-type img {\n    height: 200px;\n    margin-bottom: 2rem;\n  }\n\n  /* TOC as collapsible card on mobile */\n  #TOC, nav[role=\"doc-toc\"] {\n    position: relative;\n    margin-bottom: 2rem;\n    padding: 1rem;\n    background: var(--bs-gray-100);\n    border-radius: 8px;\n    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);\n  }\n\n  #TOC::before, nav[role=\"doc-toc\"]::before {\n    content: \"Table of Contents\";\n    display: block;\n    font-weight: 600;\n    margin-bottom: 0.5rem;\n    color: var(--bs-gray-700);\n  }\n\n  .quarto-dark #TOC,\n  .quarto-dark nav[role=\"doc-toc\"] {\n    background: rgba(255, 255, 255, 0.05);\n  }\n\n  .quarto-dark #TOC::before,\n  .quarto-dark nav[role=\"doc-toc\"]::before {\n    color: var(--bs-gray-300);\n  }\n\n  /* Code blocks mobile optimization */\n  pre {\n    font-size: 0.75rem;\n    padding: 1rem;\n    margin: 1rem -0.5rem;\n    border-radius: 4px;\n    overflow-x: auto;\n    -webkit-overflow-scrolling: touch;\n  }\n\n  /* Add visual scroll indicator for code blocks */\n  pre::after {\n    content: \"→\";\n    position: absolute;\n    right: 0.5rem;\n    top: 0.5rem;\n    color: var(--bs-gray-500);\n    font-size: 0.75rem;\n    opacity: 0;\n    transition: opacity 0.3s;\n  }\n\n  pre:hover::after {\n    opacity: 1;\n  }\n\n  /* Inline code sizing */\n  code:not(pre code) {\n    font-size: 0.85em;\n    padding: 0.1em 0.3em;\n  }\n\n  /* Callouts mobile optimization */\n  .callout {\n    margin: 1.5rem -0.5rem;\n    padding: 1rem;\n    font-size: 0.9rem;\n  }\n\n  .callout-note,\n  .callout-tip,\n  .callout-important {\n    border-left-width: 3px;\n  }\n\n  /* Images mobile optimization */\n  article img:not(article > p:first-of-type img) {\n    margin: 1.5rem -0.5rem;\n    width: calc(100% + 1rem);\n    max-width: none;\n    border-radius: 4px;\n  }\n\n  /* Lists mobile optimization */\n  ul, ol {\n    padding-left: 1.5rem;\n    margin-bottom: 1rem;\n  }\n\n  ul li, ol li {\n    margin-bottom: 0.5rem;\n  }\n\n  /* Blockquotes mobile */\n  blockquote {\n    margin: 1.5rem 0;\n    padding: 0.75rem 1rem;\n    font-size: 0.95rem;\n  }\n\n  /* Tables mobile - make them scrollable */\n  .table-responsive,\n  table {\n    display: block;\n    width: 100%;\n    overflow-x: auto;\n    -webkit-overflow-scrolling: touch;\n  }\n\n  table {\n    font-size: 0.875rem;\n    margin: 1.5rem -0.5rem;\n    width: calc(100% + 1rem);\n  }\n\n  /* Section spacing */\n  section {\n    margin: 2rem 0;\n  }\n}\n\n/* Small mobile devices (phones in portrait) */\n@media (max-width: 575px) {\n  /* Even smaller typography */\n  .title {\n    font-size: 1.5rem;\n  }\n\n  article h2 {\n    font-size: 1.35rem;\n  }\n\n  article h3 {\n    font-size: 1.15rem;\n  }\n\n  /* Minimal padding on very small screens */\n  article {\n    padding: 0.75rem;\n  }\n\n  /* Code blocks full width */\n  pre {\n    margin: 1rem -0.75rem;\n    border-radius: 0;\n    font-size: 0.7rem;\n  }\n\n  /* Images full bleed */\n  article img:not(article > p:first-of-type img) {\n    margin: 1rem -0.75rem;\n    width: calc(100% + 1.5rem);\n    border-radius: 0;\n  }\n\n  /* Hero image smaller on phones */\n  article > p:first-of-type img {\n    height: 160px;\n  }\n\n  /* Callouts full width */\n  .callout {\n    margin: 1rem -0.75rem;\n    border-radius: 0;\n  }\n\n  /* TOC compact */\n  #TOC, nav[role=\"doc-toc\"] {\n    padding: 0.75rem;\n    font-size: 0.85rem;\n  }\n\n  #TOC a, nav[role=\"doc-toc\"] a {\n    padding: 0.4rem 0;\n    padding-left: 0.75rem;\n  }\n}\n\n/* Touch-friendly enhancements */\n@media (hover: none) and (pointer: coarse) {\n  /* Larger tap targets */\n  a, button {\n    min-height: 44px;\n    min-width: 44px;\n    display: inline-flex;\n    align-items: center;\n    justify-content: center;\n  }\n\n  /* Remove hover effects on touch devices */\n  a:hover {\n    background-size: 0 2px !important;\n  }\n\n  /* Better code copy button for touch */\n  .code-copy-button {\n    padding: 0.5rem 0.75rem;\n    font-size: 0.85rem;\n  }\n}\n\n/* Landscape mobile optimization */\n@media (max-width: 991px) and (orientation: landscape) {\n  /* Reduce vertical spacing in landscape */\n  .title {\n    margin-bottom: 0.5rem;\n  }\n\n  .quarto-title-meta {\n    margin-bottom: 1.5rem;\n  }\n\n  article h2 {\n    margin-top: 1.5rem;\n    margin-bottom: 0.75rem;\n  }\n\n  /* Smaller hero image in landscape */\n  article > p:first-of-type img {\n    height: 150px;\n    margin-bottom: 1.5rem;\n  }\n}\n\n/* Focus on readability */\n::selection {\n  background: rgba(12, 133, 204, 0.2);\n  color: inherit;\n}\n\n/* Clean headings without decorations */\narticle h2::before {\n  display: none !important;\n}\n\n/* Better link styling */\narticle a {\n  color: var(--bs-primary);\n  text-decoration: none;\n  border-bottom: 1px solid transparent;\n  transition: border-color 0.2s ease;\n}\n\narticle a:hover {\n  border-bottom-color: var(--bs-primary);\n}\n\n/* Code output styling */\n.cell-output pre {\n  background: #f0f4f8;\n  border-left: 3px solid var(--bs-info);\n  font-size: 0.8rem;\n}\n\n.quarto-dark .cell-output pre {\n  background: rgba(29, 191, 224, 0.1);\n  border-left-color: var(--bs-info);\n}\n\n/* Python code cell styling */\ndiv.sourceCode {\n  margin: 1rem 0;\n}\n\n/* Improve spacing between sections */\nsection {\n  margin: 3rem 0;\n}\n\n/* Clean blockquotes */\nblockquote {\n  border-left: 3px solid var(--bs-gray-300);\n  padding-left: 1rem;\n  color: var(--bs-gray-700);\n  font-style: italic;\n  margin: 1.5rem 0;\n}\n\n.quarto-dark blockquote {\n  border-left-color: var(--bs-gray-600);\n  color: var(--bs-gray-400);\n}\n\n/* Smooth scrolling */\nhtml {\n  scroll-behavior: smooth;\n}\n\n/* Better focus states for accessibility */\na:focus,\nbutton:focus,\ninput:focus,\ntextarea:focus,\nselect:focus {\n  outline: 2px solid var(--bs-primary);\n  outline-offset: 2px;\n}\n\n/* Print styles */\n@media print {\n  pre {\n    max-height: none;\n    page-break-inside: avoid;\n  }\n\n  #TOC, nav[role=\"doc-toc\"] {\n    display: none;\n  }\n\n  article {\n    max-width: 100%;\n  }\n}\n</style>\n\n",
    "supporting": [
      "dspy-one-hour-guide_files"
    ],
    "filters": [],
    "includes": {}
  }
}