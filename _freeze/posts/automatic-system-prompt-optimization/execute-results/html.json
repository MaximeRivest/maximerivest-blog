{
  "hash": "eab6f0e9f5656b2d5637dcf2a06364b0",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Hacking DSPy into doing Automatic System Prompt Optimization\"\ndate: 2025-07-21\nauthor: Maxime Rivest\ndescription: \"In this tutorial, I will show you how to make DSPy optimize a System Prompt Automatically.\"\ndraft: false\nformat:\n  html:\n    toc: true\n    toc-location: right\n    code-tools: true\n    reference-location: margin\ninclude-in-header:\n  text: |\n    <style>\n    .cell-output-stdout {\n      overflow-y: scroll;\n      max-height: 300px;\n    }\n    </style>\ntitle-block-banner: false\ntitle-block-style: none\nexecute:\n  echo: true  \n  cache: true\n  freeze: true\n---\n\n\n::: {.callout-tip collapse=\"true\"}\n## Setting up\n\nFor this tutorial, you will only need to install dspy and setup a LLM connections. I will be using several LLMs to demonstrate how easy it is to switch between them and show the student/teacher concept. You can however set only one up if you want. If you use a locally hosted model, (you can!) simply skip the setting up of the API key. .\n\nFor this tutorial, I have will use Kimi-K2 hosted by Groq [Click here to get a groq api key](https://console.groq.com/keys) and Llama models from OpenRouter [Click here to get a OpenRouter key](https://openrouter.ai/settings/keys).\n\n::: {.callout-note icon=false appearance=\"simple\" collapse=\"true\"}\n## python library requirements\nI like to use uv to install my libraries.\n\n::: {#0bad959c .cell execution_count=1}\n``` {.python .cell-code code-fold=\"false\" code-summary=\"\"}\n!uv pip install dspy>=2.6.27\n```\n:::\n\n\n:::\n\n::: {.callout-note icon=false appearance=\"simple\" collapse=\"true\"}\n## api key setup\nI generally setup my key permanently but you can also do this to set it up just for here and now.\n\n```{{python}}\nimport os\nos.environ[\"GROQ_API_KEY\"] = \"[REDACTED]\"\nos.environ[\"OPENROUTER_API_KEY\"] = \"[REDACTED]\"\n```\n\n::: {.callout-note icon=false appearance=\"simple\" collapse=\"true\"}\n## Make GROQ_API_KEY permanent\n\nReplace GROQ_API_KEY with OPENROUTER_API_KEY to set openrouter key permanently on your system.\n\n###### Linux / macOS\nAppend to your shell start-up file (pick the one you actually use):\n\n```bash\necho \"export GROQ_API_KEY='gsk_[REDACTED]'\" >> ~/.bashrc\n# or ~/.zshrc, ~/.profile, etc.\nsource ~/.bashrc   # reload once\n```\n\n###### Windows – CMD\n```cmd\nsetx GROQ_API_KEY \"gsk_[REDACTED]\"\n```\nClose and reopen the terminal.\n\n###### Windows – PowerShell\n```powershell\n[Environment]::SetEnvironmentVariable(\"GROQ_API_KEY\", \"gsk_[REDACTED]\", \"User\")\n```\nRefresh with `refreshenv` or open a new window.\n:::\n\n:::\n\n:::\n\n## Making an automatic System Prompt tool\n\nIn this tutorial, I’ll show you how I’ve modified and customized DSPy to make it handle system prompt optimization. Usually DSPy is doing program optimization. DSPy is very much batteries included, giving you tons of tools for everything. It’s general, and it gives you a framework for how to do things, which is powerful and useful. But that framework is about AI programming, not about system prompt optimization. That is why we will need to do some customization to DSPy. Don't worry, DSPy was built in a way that lets us do it without too much work.\n\nThe nice thing about having to customize DSPy is that by the end you'll walk away with two things. First, a way to automatically optimize system prompts. Second, you'll have opened the hood: you'll understand better how DSPy works and this will help you use DSPy more proficiently when you actually want to do AI programs.\n\nSo by the end of this tutorial we will have built this simple yet powerful automatic system prompt optimization utility and understood why we had to do what we did.\n\n::: {#94faeac3 .cell execution_count=2}\n``` {.python .cell-code}\noptimzed_system_prompt = optimize(\n    training_inputs = [\"User prompt example 1\", \"...\", \"User prompt exampl n\"],\n    training_outputs = [\"Desirable Assistant's example 1\", \"...\", \"Desirable Assistant's example 1\"],\n    llm_judge = \"Return a 1 if it's good and a 0 if it's bad.\"\n)\n```\n:::\n\n\nOur `optimize` function will also be able to optionally take a starting system prompt, a max few-shots, and teacher and student model identifiers. Here is a mock-up of that:\n\n::: {#d81dbdb0 .cell execution_count=3}\n``` {.python .cell-code}\noptimzed_system_prompt = optimize(\n    training_inputs = [\"User prompt example 1\", \"...\", \"User prompt exampl n\"],\n    training_outputs = [\"Desirable Assistant's example 1\", \"...\", \"Desirable Assistant's example 1\"],\n    llm_judge = \"Return a 1 if it's good and a 0 if it's bad.\",\n    system_prompt = \"You are a model that perform well...\",\n    max_few_shots = 2,\n    teacher_model = \"a-smart-model\",\n    student_model = \"a-cheap-model\"\n)\n```\n:::\n\n\nNow that we have our vision, let's get going!\n\n## The task\n\nAll throughout this tutorial our task will be to make an English to Quebec-French translator.\n\nThe first DSPy optimizer that we want to use is `dspy.MIPROv2`. This optimizer can write (or improve) a program's instructions. Let's analyze the code below to learn what parts we must prepare to reach that goal of running MIPROv2 on task.\n\nFirst we pass `translation_judge` to the optimizer initialisation. This should be a function that must return a score between 0 (bad) to 1 (good). In DSPy these are called metrics. Almost every DSPy optimizer requires a metric. After we have 2 `max_..._demos` which are set to 0, this is because as a first run we would like to only optimise the text of the system prompt without adding few-shot examples. MIPROv2 can search for few-shot examples that would improve a program's performance.\n\n::: {#195eec83 .cell execution_count=4}\n``` {.python .cell-code}\noptimizer = dspy.MIPROv2(translation_judge, max_bootstrapped_demos = 0, max_labeled_demos = 0)\nmy_program_optimized = optimizer.compile(my_program, trainset=trainset)\n```\n:::\n\n\nSecond line of code, inside the `compile` method, we must give a DSPy `program`. This is not a string; it cannot be a system prompt. We will thus need to wrap up our system prompt + user/assistant simple LLM call into a lightweight program. And, finally, we have the trainset. In DSPy, this must be a list of `dspy.Example` objects. This is the object that all of DSPy's internals are using, so there is no way around it; we must format our input/output training set as `dspy.Example`.\n\nIn summary, we need:\n1. a metric\n2. a program\n3. a training set\n    \nand we must format those appropriately.\n\nLet's first tackle the training set as it is quite straightforward\n\n## Training set\n\nThe `Example()` object can take any arguments. You can think of those as column names in a dataframe or \"keys\" in JSON. It is usually pretty important to consider these names thoughtfully and normally DSPy will present them to the LLM as part of the prompts. In our case, that is a behavior from DSPy that we will change, so it does not matter what we call them. I decided to go with something very general. The `prompt` will be the user message and the `generation` will be the assistant message.\n\n::: {#9a1105ec .cell execution_count=5}\n``` {.python .cell-code}\nimport dspy\n\nexamples = [\n    dspy.Example(prompt=\"I'm going to the convenience store.\", generation=\"Je m'en vais au dépanneur.\"),\n    dspy.Example(prompt=\"It's really cold out today.\", generation=\"Il fait frette en maudit aujourd'hui.\"),\n    dspy.Example(prompt=\"Can you help me move this weekend?\", generation=\"Tu peux m'aider à déménager ce weekend?\"),\n    dspy.Example(prompt=\"We were stuck in traffic for two hours.\", generation=\"On était pognés dans le trafic pendant deux heures.\"),\n    dspy.Example(prompt=\"She's my girlfriend.\", generation=\"C'est ma blonde.\"),\n    dspy.Example(prompt=\"That car is so cool!\", generation=\"C'est ben l'fun ce char-là!\"),\n    dspy.Example(prompt=\"I'll call you tonight.\", generation=\"Je vais t'appeler ce soir.\"),\n    dspy.Example(prompt=\"He's always bragging.\", generation=\"Il se vente tout l'temps.\"),\n    dspy.Example(prompt=\"We grabbed a coffee at Tim's.\", generation=\"On a pris un café au Tim.\"),\n    dspy.Example(prompt=\"Close the window, it's chilly.\", generation=\"Ferme la fenêtre, y fait frette.\"),\n    dspy.Example(prompt=\"I have an appointment at 3.\", generation=\"J'ai un rendez-vous à trois heures.\"),\n    dspy.Example(prompt=\"They're celebrating their birthday.\", generation=\"Ils fêtent leur fête.\"),\n    dspy.Example(prompt=\"I parked in the back.\", generation=\"J'ai stationné dans l'fond.\"),\n    dspy.Example(prompt=\"The metro is packed.\", generation=\"Le métro est plein à craquer.\"),\n    dspy.Example(prompt=\"We watched a movie last night.\", generation=\"On a écouté un film hier soir.\"),\n    dspy.Example(prompt=\"I need to do my groceries.\", generation=\"J'dois faire mon épicerie.\"),\n    dspy.Example(prompt=\"Don't forget your boots.\", generation=\"Oublie pas tes bottes.\"),\n    dspy.Example(prompt=\"It's snowing again.\", generation=\"Il neige encore.\"),\n    dspy.Example(prompt=\"I'll take the bus.\", generation=\"J'va prendre l'bus.\"),\n    dspy.Example(prompt=\"We're out of milk.\", generation=\"On est à court de lait.\"),\n]\n```\n:::\n\n\nBefore we are done with our training set we must do 1 more little thing:\n\n::: {#129bc9fc .cell execution_count=6}\n``` {.python .cell-code}\ntrainset = [x.with_inputs('prompt') for x in examples]\n```\n:::\n\n\nThis, again, is something we have to do because of DSPy's general powerful nature. Briefly, it is used by DSPy's code internally to know what fields of the Example object are input fields for the LLM. It helps internal development to separate inputs from outputs. In our case, we just need to know that we have to do it, and so we do.\n\nLet's move on to the Metric now!\n\n## Metric\n\nOur first metric will be somewhat dumb and a little bit bad. That is because it is hard to have code that measures the quality of a translation. Despite that, we will get pretty good results, you will see.\n\nIn essence, all this code does is search for some very common French words that are not also common English words. If any of the words are found, the function returns a 1; otherwise it returns a 0.\n\n::: {#f32af04b .cell execution_count=7}\n``` {.python .cell-code}\nimport re\n\ndef is_french(text):\n    # Naive French detector: check for common French words/accents\n    french_markers = [\n        r\"\\b(le|la|les|un|une|des|du|de|et|à|est|sont|avec|pour|sur|par|mais|ou|où|que|qui|quand|comment|nous|vous|ils|elles|ça|ce|cette|ces)\\b\",\n        r\"[éèêàùçîôâœëïü]\",\n    ]\n    return any(re.search(marker, text.lower()) for marker in french_markers)\n\ndef translation_judge(example, prediction, trace=None):\n    \"\"\"\n    Return 1.0 if the output looks French, else 0.0.\n    Doing the cast explicitly guarantees we never hand DSPy a None.\n    \"\"\"\n    output = prediction.get(\"generation\", \"\") or \"\"\n    try:\n        return float(is_french(output))\n    except Exception:\n        # Anything weird is just a miss\n        return 0.0\n```\n:::\n\n\nNotice how `translation_judge` takes 3 arguments: `example`, `prediction`, and `trace`. \n\n* `example` will essentially be an instance of the `Example()` object as we defined above. \n* `prediction` will be the parsed LLM output. Usually DSPy can do a lot here, but we will modify and simplify that part too.\n* `trace` can be ignored except when we want models to generate good examples themselves. This is called bootstrapping, and in that case, if `trace` is not `None`, we must return a boolean for whether the LLM-generated example is good (1) or not (0). This could be used, for instance, to make our list of translation pairs longer.\n\nMoving on the the program now!\n\n## Program\n\nThe simplest program you can build in DSPy is one with only one input, one output, and empty instructions using `Predict`. A core concept of DSPy is around that signature, but since we do not want to do program optimization I'll not go into it (see [this post](https://maximerivest.com/posts/dspy-one-hour-guide.html) for a simple introduction to DSPy).\n\n::: {#6cb18539 .cell execution_count=8}\n``` {.python .cell-code}\nclass signature(dspy.Signature):\n    \"\"\" \n    \n    \"\"\"\n    prompt = dspy.InputField()\n    generation = dspy.OutputField()\n\ninitial_program = dspy.Predict(signature)\n```\n:::\n\n\nThe most interesting part for you to note is that `initial_program` is now callable, and if we call it, we will get an LLM response, provided we set up an LLM like this:\n\n::: {#992e6ad6 .cell execution_count=9}\n``` {.python .cell-code}\nkimi = dspy.LM(\"groq/moonshotai/kimi-k2-instruct\")\ndspy.configure(lm = kimi)\ninitial_program(prompt = \"Hello, how are you?\")\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nPrediction(\n    generation=\"I'm doing well, thank you for asking! How can I help you today?\"\n)\n```\n:::\n:::\n\n\nBut we have a few problems.\n\n::: {#758a07fa .cell execution_count=10}\n``` {.python .cell-code}\ninitial_program.inspect_history()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\n\n\n[2025-07-23T09:37:55.419674]\n\nSystem message:\n\nYour input fields are:\n1. `prompt` (str):\nYour output fields are:\n1. `generation` (str):\nAll interactions will be structured in the following way, with the appropriate values filled in.\n\n[[ ## prompt ## ]]\n{prompt}\n\n[[ ## generation ## ]]\n{generation}\n\n[[ ## completed ## ]]\nIn adhering to this structure, your objective is:\n\n\nUser message:\n\n[[ ## prompt ## ]]\nHello, how are you?\n\nRespond with the corresponding output fields, starting with the field `[[ ## generation ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n\n\nResponse:\n\n[[ ## generation ## ]]\nI'm doing well, thank you for asking! How can I help you today?\n\n[[ ## completed ## ]]\n\n\n\n\n\n```\n:::\n:::\n\n\nThe above command prints the previous interaction we had with the LLM. In that interaction, the system prompt was:\n\n\n```{text}\nYour input fields are:\n1. `prompt` (str):\nYour output fields are:\n1. `generation` (str):\nAll interactions will be structured in the following way, with the appropriate values filled in.\n\n[[ ## prompt ## ]]\n{prompt}\n\n[[ ## generation ## ]]\n{generation}\n\n[[ ## completed ## ]]\nIn adhering to this structure, your objective is:\n```\n\n\nAnd the user message was:\n\n\n```{text}\n[[ ## prompt ## ]]\nHello, how are you?\n\nRespond with the corresponding output fields, starting with the field `[[ ## generation ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n```\n\n\nAnd the assistant was:\n\n\n```{text}\n[[ ## generation ## ]]\nI'm doing well, thank you for asking! How can I help you today?\n\n[[ ## completed ## ]]\n```\n\n\nA lot of stuff was added, and if we run an optimizer as it is, we will be optimizing the LLM's performance in that prompt template. This is a little too different from the vanilla we would have expected, which is:\n`sp = \"\"`,\n`user = \"Hello, how are you?\"`,\nand the assistant response could have been something like\n`assistant = \"I'm doing well, thank you for asking! How can I help you today?\"`.\nThe culprit for the additions is DSPy's adapter. The adapter is amazing at turning a DSPy signature into an AI program, but right now, it's in the way.\n\nLet's replace DSPy's adapter with our own simplified version.\n\n## Making a Simple Custom Adapter\n\nAdapters are DSPy's interface to the LLMs. They are called with a few pieces of information, and DSPy expects a parsed LLM generation to be returned. The following is the simplest we can make an adapter. We are taking in the LM that DSPy's internals want us to use, keyword arguments if any, a signature, demos, and inputs.\n\nThe signature can contain only 3 things: instructions, inputs, and outputs. In our case, we have \"canned\" the signature, so we also know that the input is named `prompt` and the output is named `generation`, simplifying our requirements for our adapter substantially from what DSPy usually has to worry about.\n\n::: {#3aaf18bb .cell execution_count=11}\n``` {.python .cell-code}\n# Define the SimplestAdapter as before\nclass SimplestAdapter(dspy.Adapter):\n    def __call__(self, lm, lm_kwargs, signature, demos, inputs):\n        print(inputs)\n        system_content = signature.instructions\n        if demos:\n            system_content\n        messages = [\n            {\"role\": \"system\", \"content\": system_content},\n            {\"role\": \"user\", \"content\": inputs[\"prompt\"]},\n        ]\n        outputs = lm(messages=messages, **lm_kwargs)\n        return [{\"generation\": outputs[0]}]\n\n# Do NOT call dspy.configure(adapter=SimplestAdapter())\n# Subclass Predict to use the custom adapter only for this instance\nclass MyPredict(dspy.Predict):\n    def forward(self, **kwargs):\n        adapter = SimplestAdapter()\n        with dspy.settings.context(adapter=adapter):\n            return super().forward(**kwargs)\n```\n:::\n\n\nWe also have to subclass `dspy.Predict` so that we are able to make a program that uses our adapter. Usually in DSPy, the adapter is set globally or within a scoped context, but in both cases, the adapter is applied recursively. This has the effect of making some DSPy programs inside the optimizer use our simple adapter, causing them all to break. And breaking everything is generally not good...\n\n::: {#1f15f5b1 .cell execution_count=12}\n``` {.python .cell-code}\nmy_program = MyPredict(signature)\n```\n:::\n\n\n## Automatically Generating a System Prompt\n\nWe are now ready to run the optimizer!!!\n\n### Letting MIPROv2 write the System Prompt\n\n::: {#70a5b0b2 .cell execution_count=13}\n``` {.python .cell-code}\noptimizer = dspy.MIPROv2(translation_judge, max_bootstrapped_demos = 0, max_labeled_demos = 0)\nmy_program_optimized = optimizer.compile(my_program, trainset=trainset, requires_permission_to_run = False)\n```\n:::\n\n\nLet's test the program right away:\n\n::: {#6b7a5f09 .cell execution_count=14}\n``` {.python .cell-code}\nmy_program_optimized(prompt = \"Hello, how are you?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'prompt': 'Hello, how are you?'}\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\nPrediction(\n    generation='Salut, ça va-tu ben?'\n)\n```\n:::\n:::\n\n\nGood! It's a translation and not a response to our salutation. Let's inspect the messages.\n\n::: {#e9416c3e .cell execution_count=15}\n``` {.python .cell-code}\nmy_program_optimized.inspect_history()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\n\n\n[2025-07-23T09:37:56.428724]\n\nSystem message:\n\nYou are a seasoned Québécois street linguist who grew up in Montréal’s Plateau-Mile End. Your job is to translate the user’s colloquial North-American English sentence into equally relaxed, idiomatic Québec French. Preserve every ounce of slang, contraction, and colourful swear word that a native speaker would use at the dépanneur counter on a Friday night. Keep the same tone, brevity, and punch as the original—no extra formality, no explanations, just the straight-up spoken French you’d hear in a Montréal alleyway.\n\n\nUser message:\n\nHello, how are you?\n\n\nResponse:\n\nSalut, ça va-tu ben?\n\n\n\n\n\n```\n:::\n:::\n\n\nAnd this confirms that our adapter works! This is a completely 'vanilla' set of messages.\n\n### Using LLM in the Metric\n\nHere we redefine our `translation_judge`, so that instead of using Python code to calculate a score between 0 and 1, we ask an LLM to do that.\n\nIn this case, we are using DSPy in its most natural way! So first we define a signature by subclassing `dspy.Signature`.\n\nThe docstring there is the instruction that the adapter will put in a system prompt. The InputFields are those we will pass to the program, and the OutputFields are those that the program will return. In the case of `score: int = dspy.OutputField(desc=\"A single integer from 1 to 5.\")`, DSPy will ensure and parse the integer out of the LLM-generated string for us. If an integer is not provided, DSPy will even retry for us, and try different adapters.\n\n::: {#442fdcf7 .cell execution_count=16}\n``` {.python .cell-code}\nclass QuebecTranslationJudge(dspy.Signature):\n    \"\"\"You are an expert Quebec French linguist. For each English sentence and its proposed French translation, evaluate the translation on a scale of 1 to 5 based on the following criteria, with 5 being a perfect, natural-sounding translation.\n\n1.  **Accuracy**: Does the French convey the same meaning as the English?\n2.  **Register**: Is the tone appropriately informal/colloquial (not formal textbook French)?\n3.  **Regional Vocabulary**: Does it use authentic Quebec French terms (e.g., \"dépanneur\", \"frette\", \"char\")?\n4.  **Contractions**: Are natural Quebec French contractions used (e.g., \"j'va\", \"t'sais\", \"y fait\")?\n5.  **Proper Nouns & Anglicisms**: Are names (e.g., \"Tim's\") and common anglicisms (e.g., \"weekend\") handled appropriately for Quebec French?\n\nProvide brief feedback on any issues and output only the final numerical score.\n\nIMPORTANT IF MEANING IS CHANGED SET TO 0.\n\"\"\"\n\n    english_sentence = dspy.InputField(desc=\"The original sentence in English.\")\n    french_translation = dspy.InputField(desc=\"The proposed translation in Quebec French.\")\n    feedback = dspy.OutputField(desc=\"Brief feedback on the translation's quality.\")\n    score: int = dspy.OutputField(desc=\"A single integer from 1 to 5.\")\n\n# If you have a capable model configured globally, just do this:\nllm_judge = dspy.Predict(QuebecTranslationJudge)\n\ndef translation_judge(example, prediction, trace=None):\n    \"\"\"\n    An LLM-based metric that judges translation quality.\n    It robustly parses the score and normalizes it to a 0.0-1.0 scale.\n    \"\"\"\n    english_sentence = example.prompt\n    # Ensure the prediction's output is not empty\n    french_translation = prediction.get(\"generation\", \"\")\n    if not french_translation:\n        return 0.0\n\n    try:\n        # Call the LLM judge to get a score\n        result = llm_judge(\n            english_sentence=english_sentence,\n            french_translation=french_translation\n        )\n        # Parse the score and normalize it to a 0.0-1.0 range\n        # (e.g., a score of 5 becomes 1.0, 1 becomes 0.2)\n        score = float(result.score)\n        return score / 5.0\n    except (ValueError, AttributeError, TypeError):\n        # If the LLM fails to output a valid score, return 0.0\n        return 0.0\n```\n:::\n\n\nNow that we have overwritten `translation_judge`, let's run the optimization again.\n\n::: {#71260033 .cell execution_count=17}\n``` {.python .cell-code}\noptimizer = dspy.MIPROv2(translation_judge, max_bootstrapped_demos = 0, max_labeled_demos = 0)\nmy_program_optimized = optimizer.compile(my_program, trainset=trainset, requires_permission_to_run = False)\n```\n:::\n\n\nLet's test the program right away:\n\n::: {#9f70faf4 .cell execution_count=18}\n``` {.python .cell-code}\nmy_program_optimized(prompt = \"Hello, how are you?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'prompt': 'Hello, how are you?'}\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\nPrediction(\n    generation='Salut, ça va-tu?'\n)\n```\n:::\n:::\n\n\nGood! It's again a translation and not a response to our salutation. Let's inspect the messages.\n\n::: {#d6c8ae67 .cell execution_count=19}\n``` {.python .cell-code}\nmy_program_optimized.inspect_history()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\n\n\n[2025-07-23T09:37:57.484071]\n\nSystem message:\n\nTranslate the given colloquial North-American English sentence into natural, spoken Québec French. Preserve the tone, brevity, and regional flavor—use contractions, slang like “dépaneur”, and expressive modifiers such as “en maudit” where they fit naturally. Return only the French translation.\n\n\nUser message:\n\nHello, how are you?\n\n\nResponse:\n\nSalut, ça va-tu?\n\n\n\n\n\n```\n:::\n:::\n\n\nAnd this confirms that our adapter works! This is a completely 'vanilla' set of messages.\n\n### Optimizing with Few-Shot Examples too\n\nLet's now make it possible for MIPROv2 to also add few-shot examples into the system prompt.\n\nFor this, we need to improve our simple adapter to have a way to format the demos. So we first define `format_demos`. This is a normal Python function that will expect a list of DSPy Examples and turn that into a simple string with a light XML structure.\n\n::: {#ea20caf4 .cell execution_count=20}\n``` {.python .cell-code}\ndef format_demos(demos):\n    \"\"\"\n    Wrap every demo once – no duplicated header lines.\n    \"\"\"\n    parts = [\"Here are examples of your expected behavior.\",\n             \"<examples>\"]\n    for i, demo in enumerate(demos, 1):\n        parts += [\n            f\"<example_{i}>\",\n            \"User:\",\n            demo[\"prompt\"],\n            \"Assistant:\",\n            demo[\"generation\"],\n            f\"</example_{i}>\",\n        ]\n    parts.append(\"</examples>\")\n    return \"\\n\".join(parts)\n```\n:::\n\n\nLet's try it:\n\n::: {#5253d296 .cell execution_count=21}\n``` {.python .cell-code}\nexamples = [\n    dspy.Example(prompt=\"She's my girlfriend.\", generation=\"C'est ma blonde.\"),\n    dspy.Example(prompt=\"It's snowing again.\", generation=\"Il neige encore.\"),\n]\n\nprint(format_demos(examples))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHere are examples of your expected behavior.\n<examples>\n<example_1>\nUser:\nShe's my girlfriend.\nAssistant:\nC'est ma blonde.\n</example_1>\n<example_2>\nUser:\nIt's snowing again.\nAssistant:\nIl neige encore.\n</example_2>\n</examples>\n```\n:::\n:::\n\n\nAnd we need to update our `SimplestAdapter` with this line:\n`system_content += \"\\n\" + format_demos(demos)`.\n\n::: {#b9820049 .cell execution_count=22}\n``` {.python .cell-code}\n# Define the SimplestAdapter as before\nclass SimplestAdapter(dspy.Adapter):\n    def __call__(self, lm, lm_kwargs, signature, demos, inputs):\n        print(inputs)\n        system_content = signature.instructions\n        if demos:\n            system_content += \"\\n\" + format_demos(demos)\n        messages = [\n            {\"role\": \"system\", \"content\": system_content},\n            {\"role\": \"user\", \"content\": inputs[\"prompt\"]},\n        ]\n        outputs = lm(messages=messages, **lm_kwargs)\n        return [{\"generation\": outputs[0]}]\n```\n:::\n\n\nLet's run the optimization again, but with `max_labeled_demos = 3` this time.\n\n::: {#4ce839ca .cell execution_count=23}\n``` {.python .cell-code}\noptimizer = dspy.MIPROv2(translation_judge, max_bootstrapped_demos = 3, max_labeled_demos = 3)\nmy_program_optimized = optimizer.compile(my_program, trainset=trainset, requires_permission_to_run = False)\n```\n:::\n\n\nLet's test the program right away:\n\n::: {#3ed125a3 .cell execution_count=24}\n``` {.python .cell-code}\nmy_program_optimized(prompt = \"Hello, how are you?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'prompt': 'Hello, how are you?'}\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\nPrediction(\n    generation='Salut, ça va?'\n)\n```\n:::\n:::\n\n\nGood! It's again a translation and not a response to our salutation. Let's inspect the messages.\n\n::: {#4d9f6a81 .cell execution_count=25}\n``` {.python .cell-code}\nmy_program_optimized.inspect_history()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\n\n\n[2025-07-23T09:37:59.087720]\n\nSystem message:\n\nTranslate the following English sentence into colloquial Québec French exactly as it would be spoken in daily conversation. Preserve the tone, brevity, and any slang or contractions typical of spoken Québécois. Return only the French translation—no explanations, no quotation marks, no extra formatting.\nHere are examples of your expected behavior.\n<examples>\n<example_1>\nUser:\nI'm going to the convenience store.\nAssistant:\nJ'm'en va au dépanneur.\n</example_1>\n<example_2>\nUser:\nWe were stuck in traffic for two hours.\nAssistant:\nOn était pognés dans le trafic pendant deux heures.\n</example_2>\n<example_3>\nUser:\nCan you help me move this weekend?\nAssistant:\nTu peux m'aider à déménager ce weekend?\n</example_3>\n</examples>\n\n\nUser message:\n\nHello, how are you?\n\n\nResponse:\n\nSalut, ça va?\n\n\n\n\n\n```\n:::\n:::\n\n\nNow our system prompt also contains a few examples.\n\n### Changing Optimizer\n\nWe can easily change the optimizer. Look at this code that now uses `SIMBA` instead of `MIPROv2`.\n\n::: {#ae44894b .cell execution_count=26}\n``` {.python .cell-code}\noptimizer = dspy.SIMBA(metric = translation_judge, bsize = 8)\nmy_program_optimized = optimizer.compile(my_program, trainset=trainset)\n```\n:::\n\n\nLet's check the results:\n\n::: {#6c066488 .cell execution_count=27}\n``` {.python .cell-code}\nmy_program_optimized(prompt = \"Hello, how are you?\")\nmy_program_optimized.inspect_history()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'prompt': 'Hello, how are you?'}\n\n\n\n\n[2025-07-23T09:38:14.219315]\n\nSystem message:\n\nIf the prompt contains a simple declarative sentence in English (like \"They're celebrating their birthday.\"), then you should output a direct French translation of that exact sentence, not conversational filler or advice. Focus on translating the meaning word-for-word while maintaining proper French grammar and vocabulary.\n\nIf the prompt is an enthusiastic English sentence about something being cool or awesome, then you should translate it into informal, spoken Québec French rather than standard European French. Use colloquial expressions like \"ben l'fun\", \"char\" for \"car\", and \"ce …-là\" constructions to sound natural to a Québec audience.\n\nIf the prompt is any English sentence (even a neutral declarative one like \"He's always bragging.\"), then you should translate it into informal Québec French: contract \"il\" to \"y'\", drop the article \"le\" to \"l'\", use colloquial expressions such as \"tout l'temps\" and \"en train de\", and pick Québec-specific verbs like \"fanfaronner\" instead of standard French \"se vanter\".\n\nIf the prompt is a neutral declarative sentence that mentions a specific clock time (e.g., \"at 3\", \"at 7:30\"), then you should render that time in the informal Québec-French way: use numerals followed by \"h\" (e.g., \"3h\", \"7h30\") instead of spelling out the hour in words.\nHere are examples of your expected behavior.\n<examples>\n<example_1>\nUser:\nCan you help me move this weekend?\nAssistant:\nTu peux m’aider à déménager ce week-end ?\n</example_1>\n</examples>\n\n\nUser message:\n\nHello, how are you?\n\n\nResponse:\n\nSalut, ça va ?\n\n\n\n\n\n```\n:::\n:::\n\n\nIn the case of SIMBA, we can see that it gradually added instructions to the system prompt.\n\n### Teacher-Student optimization\n\nLet's now optimize for a smaller model while still using `Kimi` to generate the system prompt.\n\nWe must now create another LM connection. Let's stay with Groq for speed and to keep things simple.\n\n::: {#820a99e8 .cell execution_count=28}\n``` {.python .cell-code}\nllama8b = dspy.LM(\"groq/llama-3.1-8b-instant\")\nmy_program.set_lm(lm = llama8b)\n```\n:::\n\n\nHere, I have to add the teacher argument to compile: `.compile(..., teacher=kimi, ...)`.\n\n::: {#8b30fe5e .cell execution_count=29}\n``` {.python .cell-code}\noptimizer = dspy.MIPROv2(translation_judge, max_bootstrapped_demos = 0, max_labeled_demos = 0)\nmy_program_optimized = optimizer.compile(my_program, trainset=trainset, teacher = kimi, requires_permission_to_run = False)\n```\n:::\n\n\nLet's confirm that `my_program_optimized` is set to use Llama.\n\n::: {#d1102761 .cell execution_count=30}\n``` {.python .cell-code}\nmy_program_optimized.lm.model\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```\n'groq/llama-3.1-8b-instant'\n```\n:::\n:::\n\n\nIndeed it is!\n\nLet's try it:\n\n::: {#ddb2b241 .cell execution_count=31}\n``` {.python .cell-code}\nmy_program_optimized(prompt = \"Hello, how are you?\")\nmy_program_optimized.inspect_history()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'prompt': 'Hello, how are you?'}\n\n\n\n\n[2025-07-23T09:38:15.394238]\n\nSystem message:\n\nTranslate the following informal North-American English sentence into equally informal, colloquial Québec French. Preserve the brevity, tone, and intent of the original. Use authentic Québécois phrasing, contractions, regional slang (e.g., “dépaneur”, “char”), and swear intensifiers (“en maudit”) where appropriate. Do not add or omit information.\n\n\nUser message:\n\nHello, how are you?\n\n\nResponse:\n\nSalut, comment ça va?\n\n\n\n\n\n```\n:::\n:::\n\n\nCool, so now we have Llama 3.1 8b as our translator :)\n\n### Bringing It All Together\n\nLet's now make the `optimize()` function we envisioned at the beginning.\n\nHere, I asked o3-pro to bring it all together for us. You'll recognize its comment style.\n\n::: {#51e8007f .cell execution_count=32}\n`````````` {.python .cell-code}\ndef optimize(\n    *,\n    training_inputs: list[str],\n    training_outputs: list[str],\n    llm_judge,\n    system_prompt: str = \"\",\n    max_few_shots: int = 0,\n    teacher_model=None,\n    student_model=None,\n):\n    \"\"\"\n    One‑stop helper that (1) turns parallel input / output lists into a DSPy\n    training‑set, (2) builds / optimises a tiny translation programme, and\n    (3) returns the auto‑generated system‑prompt (with optional few‑shot\n    examples baked‑in).\n\n    Parameters\n    ----------\n    training_inputs, training_outputs : list[str]\n        Parallel lists of user prompts and the desired assistant replies.\n    llm_judge : str | Callable\n        Either a *string* with judging instructions **or** a fully‑formed\n        `metric(example, prediction, trace)->float` callable.\n    system_prompt : str, optional\n        A starting prompt to improve upon (default empty).\n    max_few_shots : int, optional\n        Upper‑bound on examples the optimiser may add to the prompt.\n    teacher_model, student_model : str | dspy.LM | None\n        Identifiers *or* `dspy.LM` objects.  If only one is given, we fall\n        back gracefully to the globally configured LM.\n\n    Returns\n    -------\n    str\n        The final system‑prompt text, ready to feed any chat‑completion API.\n    \"\"\"\n\n    # ------------------------------------------------------------------ #\n    # 0 .  Basic validation                                              #\n    # ------------------------------------------------------------------ #\n    if len(training_inputs) != len(training_outputs):\n        raise ValueError(\"`training_inputs` and `training_outputs` must \"\n                         \"have the same length.\")\n\n    # ------------------------------------------------------------------ #\n    # 1 .  Build the training set                                        #\n    # ------------------------------------------------------------------ #\n    examples = [\n        dspy.Example(prompt=inp, generation=out)\n        for inp, out in zip(training_inputs, training_outputs, strict=True)\n    ]\n    trainset = [ex.with_inputs(\"prompt\") for ex in examples]\n\n    # ------------------------------------------------------------------ #\n    # 2 .  Build (or wrap) the metric                                    #\n    # ------------------------------------------------------------------ #\n    if callable(llm_judge):\n        translation_judge = llm_judge\n    else:\n        # Dynamically build a judge signature around the instruction string.\n        judge_instructions = str(llm_judge).strip()\n\n        class _AutoJudge(dspy.Signature):\n            \"\"\"{0}\"\"\".format(judge_instructions)\n            english_sentence = dspy.InputField()\n            french_translation = dspy.InputField()\n            score: int = dspy.OutputField(desc=\"0 = bad, 1 = good\")\n\n        judge_predict = dspy.Predict(_AutoJudge)\n\n        def translation_judge(example, prediction, trace=None):\n            try:\n                result = judge_predict(\n                    english_sentence=example.prompt,\n                    french_translation=prediction.get(\"generation\", \"\")\n                )\n                return float(result.score)\n            except Exception:\n                return 0.0\n\n    # ------------------------------------------------------------------ #\n    # 3 .  Prepare the LM objects                                        #\n    # ------------------------------------------------------------------ #\n    def _to_lm(obj):\n        if obj is None:\n            return None\n        return obj if isinstance(obj, dspy.LM) else dspy.LM(obj)\n\n    teacher_lm = _to_lm(teacher_model)\n    student_lm = _to_lm(student_model)\n\n    # If the reader supplied no student, fall back to whatever DSPy is\n    # already configured with; otherwise bind the student to our programme.\n    if student_lm is not None:\n        active_lm = student_lm\n    else:\n        active_lm = dspy.settings.get(\"lm\")  # may still be None → DSPy default\n\n    # ------------------------------------------------------------------ #\n    # 4 .  Build the programme                                           #\n    # ------------------------------------------------------------------ #\n    class OptimSignature(dspy.Signature):\n        \"\"\"{0}\"\"\".format(system_prompt)\n        prompt = dspy.InputField()\n        generation = dspy.OutputField()\n\n    programme = MyPredict(OptimSignature)\n    if active_lm is not None:\n        programme.set_lm(active_lm)\n\n    # ------------------------------------------------------------------ #\n    # 5 .  Run MIPRO‑v2                                                  #\n    # ------------------------------------------------------------------ #\n    optimiser = dspy.MIPROv2(\n        translation_judge,\n        max_bootstrapped_demos=max_few_shots,\n        max_labeled_demos=max_few_shots,\n    )\n\n    compile_kwargs = dict(\n        trainset=trainset,\n        requires_permission_to_run=False\n    )\n    if teacher_lm is not None:\n        compile_kwargs[\"teacher\"] = teacher_lm\n\n    tuned_prog = optimiser.compile(programme, **compile_kwargs)\n\n    # ------------------------------------------------------------------ #\n    # 6 .  Extract the finished prompt (+ optional demos)                #\n    # ------------------------------------------------------------------ #\n    final_prompt = tuned_prog.signature.instructions.strip()\n\n    if getattr(tuned_prog, \"demos\", None):\n        final_prompt += \"\\n\" + format_demos(tuned_prog.demos)\n\n    return final_prompt\n``````````\n:::\n\n\nLet's use it:\n\n::: {#9b70a1f2 .cell execution_count=33}\n``` {.python .cell-code}\noptimized_system_prompt = optimize(\n    training_inputs=[\n        \"I'm going to the convenience store.\",\n        \"It's really cold out today.\"\n    ],\n    training_outputs=[\n        \"Je m'en vais au dépanneur.\",\n        \"Il fait frette en maudit aujourd'hui.\"\n    ],\n    llm_judge=\"Return 1 if the French looks natural and 0 otherwise.\"\n)\n```\n:::\n\n\nLet's see what system prompt we got:\n\n::: {#154d23b6 .cell execution_count=34}\n``` {.python .cell-code}\nprint(optimized_system_prompt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nYou are an expert Canadian-French translator who specializes in ultra-casual, idiomatic language.  \nGiven a short English sentence or phrase (the `prompt`), produce its Canadian-French equivalent (`generation`) that is just as informal and succinct. Preserve slang, contractions, and the exact tone of the original—no extra formality, no extra words.\n```\n:::\n:::\n\n\nNot bad! Let's test with all the parameters:\n\n::: {#aef0eb20 .cell execution_count=35}\n``` {.python .cell-code}\noptimized_system_prompt = optimize(\n    training_inputs=[\n        \"I'm going to the convenience store.\",\n        \"It's really cold out today.\"\n    ],\n    training_outputs=[\n        \"Je m'en vais au dépanneur.\",\n        \"Il fait frette en maudit aujourd'hui.\"\n    ],\n    llm_judge=\"Return 1 if the French looks natural and French Canadian and 0 otherwise.\",\n    system_prompt = \"Translate from english to french\",\n    max_few_shots = 2,\n    teacher_model = \"groq/moonshotai/kimi-k2-instruct\",\n    student_model = \"groq/llama-3.1-8b-instant\"\n)\n```\n:::\n\n\nAnd let's see what we got:\n\n::: {#0845cb02 .cell execution_count=36}\n``` {.python .cell-code}\nprint(optimized_system_prompt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nYou are a bilingual Canadian-French speaker who translates casual English into the colloquial, idiomatic French used in everyday Québec conversations.  Given the prompt (an English sentence or short paragraph), return the generation: its natural-sounding, equally informal Canadian-French equivalent, keeping the same register, brevity, and tone.\n```\n:::\n:::\n\n\n",
    "supporting": [
      "automatic-system-prompt-optimization_files"
    ],
    "filters": [],
    "includes": {}
  }
}